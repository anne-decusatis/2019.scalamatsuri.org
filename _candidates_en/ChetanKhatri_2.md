---
name: Chetan Khatri
title: "Traditional Relational DW to Distributed DW with the power of Spark and Scala"
length: 40
audience: Beginner
language: English
twitter: khatri_chetan
github: chetkhatri
icon: https://s.gravatar.com/avatar/4c0ea55b34c2b6f50c32024b750c7161?s=80
organization: Accionlabs Inc.
tags:
  - Big Data / Fast Data
  - Functional Programming
  - Best Practices
suggestions:
  - 1. Who understands basic functional programming with scala or has an understanding of Java.
  - 2. Who understands concurrent programming or multithreading in Java / Scala.
  - 3. Who has interest in distributed data processing and has a keen interest in data scaling optimization.
  - 4. Who has earlier worked in Big Data, Fast Data or has a keen interest.
contributes:
  - Apache Spark
  - Apache HBase
  - Apache MXNet
speaker_experience:
  - TransmogrifAI - Automate Machine Learning Workflow with the power of Scala and Spark at massive scale. - Scala.IO 2018 Lyon, France.
  - Scaling 30 TB's of Data lake with Apache HBase and Scala DSL at Production. - HBaseConAsia 2018, Beijing - China.
  - Scaling TB's of data with Apache Spark and Scala DSL at Production - HKOSCon 2018
---
At the moment still, so many enterprise organizations are relying on the traditional relational data warehouse. Organization’s large amount of transactional data gets persisted in the relational data warehouse. Also for the purpose of analytics but with the tremendous growth of Data, need of high availability of analytical data for the business and obviously need of fast data processing. Organizations have started to think about “Re-engineering data platforms”.
 “Scala” and Apache Spark became very popular tools to build modern distributed analytical platforms.
